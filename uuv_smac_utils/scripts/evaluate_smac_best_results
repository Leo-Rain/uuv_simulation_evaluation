#!/usr/bin/env python
# Copyright (c) 2016 The UUV Simulator Authors.
# All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import argparse
import roslib
import rospy
import json
import os
import sys
import yaml
import numpy as np
from time import sleep
from uuv_simulation_runner import SimulationRunner
from uuv_bag_evaluation import Evaluation
from uuv_bag_evaluation.metrics import KPI
from uuv_cost_function import CostFunction
from uuv_smac_utils import OptConfiguration, start_simulation_pool, stop_simulation_pool
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

roslib.load_manifest('uuv_smac_utils')

def run_simulation(idx, smac_results, output_dir):
    smac_result = json.loads(smac_results[-1])
    sub_result_folder = os.path.join(os.getcwd(), output_dir, str(idx))

    result_folders[len(smac_results) - 1] = dict()

    if not os.path.isdir(sub_result_folder):
        os.makedirs(sub_result_folder)

    # Store the partial result in the folder
    with open(os.path.join(sub_result_folder, 'partial_result.json'), 'w') as p_res:
        p_res.write(json.dumps(smac_result))

    parsed_params = dict()

    for item in smac_result['incumbent']:
        tag, value = item.split('=')
        parsed_params[tag] = float(value[1:-1])

    opt_config.params = parsed_params
    opt_config.results_dir = sub_result_folder

    failed_tasks = list()
    output, failed_tasks = start_simulation_pool(1, output_dir=sub_result_folder)

    print output
    return output

def plot_trajectories(results, output_dir):
    ########################################################################
    # Compare first and last trajectories
    ########################################################################

    opt_config = OptConfiguration.get_instance()

    fig = plt.figure(figsize=(12, 8))
    ax = fig.gca(projection='3d')

    time_offset = max(0.0, opt_config.evaluation_time_offset)

    for task in opt_config.tasks:
        task_name = task.split('/')[-1]
        task_name = task_name.split('.')[0]

        trajplot_dir = os.path.join(output_dir, 'trajectories', task_name)

        sim_eval = Evaluation(results[0]['recording_filename'],
                            results[0]['results_dir'],
                            time_offset=time_offset)

        if desired is None:
            desired = sim_eval.recording.parsers['trajectory'].reference.points

        traj = sim_eval.recording.parsers['trajectory'].odometry.points

        ax.plot(
            [d.x for d in desired],
            [d.y for d in desired],
            [d.z for d in desired], 'b--', label='Desired path', linewidth=3)
        ax.plot(
            [d.x for d in traj],
            [d.y for d in traj],
            [d.z for d in traj], 'g', label='Initial set', linewidth=3)

        sim_eval = Evaluation(results[1]['recording_filename'],
                            results[1]['results_dir'],
                            time_offset=time_offset)

        traj = sim_eval.recording.parsers['trajectory'].odometry.points

        ax.plot(
            [d.x for d in traj],
            [d.y for d in traj],
            [d.z for d in traj], 'r', label='Optimal set', linewidth=3)

        ax.set_xlabel('X [m]', fontsize=20)
        ax.set_ylabel('Y [m]', fontsize=20)
        ax.set_zlabel('Z [m]', fontsize=20)

        ax.tick_params(axis='x', labelsize=18)
        ax.tick_params(axis='y', labelsize=18)
        ax.tick_params(axis='z', labelsize=18)

        ax.xaxis.labelpad = 10
        ax.yaxis.labelpad = 10
        ax.zaxis.labelpad = 10

        ax.legend(loc='upper left', fancybox=True, framealpha=0.8, fontsize=18)
        ax.grid(True)
        plt.tight_layout()

        filename = os.path.join(trajplot_dir, 'trajectories_comparison.pdf')
        plt.savefig(filename)
        plt.close(fig)

def plot_cost(results_filename, output_dir):
    with open(results_filename, 'r') as s_file:
        for line in s_file:
            smac_result = json.loads(line)
            cost.append(smac_result['cost'])
            evals.append(smac_result['evaluations'])

    ########################################################################
    # Plot cost function evolution
    ########################################################################

    # SMAC's first two runs are always the same
    cost[0] = cost[1]
    fig = plt.figure(figsize=(6, 4))
    ax = fig.add_subplot(111)

    ax.plot(evals, cost, '--b', linewidth=3, zorder=1)
    ax.scatter(evals, cost, s=60, color='red', zorder=2)

    ax.set_xlabel('Number of evaluations', fontsize=20)
    ax.set_ylabel('Cost function', fontsize=20)
    ax.tick_params(axis='both', labelsize=18)
    ax.grid(True)
    ax.set_xlim(np.min(evals), np.max(evals))
    plt.tight_layout()

    filename = os.path.join(output_dir, 'smac_evolution.pdf')
    plt.savefig(filename)
    plt.close(fig)

    del fig

def plot_kpis():
    pass
    # ########################################################################
    # # Compare first and last KPIs
    # ########################################################################

    # fig = plt.figure(figsize=(8, 12))

    # kpi_labels = dict(rmse_position='RMS Error - Position',
    #                     rmse_yaw='RMS Error - Yaw',
    #                     rmse_linear_velocity='RMS Error - Linear velocity',
    #                     rmse_angular_velocity='RMS Error - Angular velocity',
    #                     mean_abs_thrust='Mean abs. thrust')

    # i = 1
    # for tag in kpi_labels:
    #     ax = fig.add_subplot(len(kpi_labels.keys()), 1, i)
    #     ax.plot(np.arange(idx), [kpi_results[k][tag] for k in np.arange(idx)], '--b', linewidth=2, zorder=1)
    #     ax.scatter(np.arange(idx), [kpi_results[k][tag] for k in np.arange(idx)], s=30, color='red', zorder=2)
    #     i += 1

    #     ax.set_xlabel('Set index', fontsize=20)
    #     ax.set_ylabel('Metric value', fontsize=20)
    #     ax.set_title(kpi_labels[tag], fontsize=22)
    #     ax.tick_params(axis='both', labelsize=15)
    #     ax.grid(True)
    #     ax.set_xlim(0, idx - 1)

    # plt.tight_layout()
    # filename = os.path.join(args.output_dir, 'kpis_comparison.pdf')
    # plt.savefig(filename)
    # plt.clf()

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Evaluation of best SMAC output')
    parser.add_argument(
        '--input_dir',
        type=str,
        default='.')
    parser.add_argument(
        '--output_dir',
        type=str,
        default='best_results')
    parser.add_argument(
        '--simulate',
        type=int,
        default='1')

    # Parse input arguments
    args = parser.parse_args(rospy.myargv()[1:])

    smac_folder = None
    for item in os.listdir(args.input_dir):
        if 'smac' in item:
            if os.path.isdir(os.path.join(args.input_dir, item)):
                smac_folder = os.path.join(args.input_dir, item)

    if smac_folder is None:
        raise Exception('No SMAC output folder found')

    print 'SMAC RESULTS FOLDER=', smac_folder

    for f in os.listdir(smac_folder):
        if f == 'traj_aclib2.json':
            smac_file = os.path.join(smac_folder, 'traj_aclib2.json')
            break
        if os.path.isdir(os.path.join(smac_folder, f)):
            for a in os.listdir(os.path.join(smac_folder, f)):
                if a == 'traj_aclib2.json':
                    smac_file = os.path.join(smac_folder, f, a)
    if not os.path.isfile(smac_file):
        raise Exception('SMAC output file not found')

    print 'SMAC OUTPUT FILE=', smac_file

    if not os.path.isdir(args.output_dir):
        os.makedirs(args.output_dir)

    # Load optimization configuration
    with open(os.path.join(args.input_dir, 'opt_config.yml'), 'r') as c_file:
        opt_config = yaml.load(c_file)

    opt_config = OptConfiguration.get_instance(os.path.join(args.input_dir, 'opt_config.yml'))
    opt_config.record_all = True
    opt_config.store_kpis_only = False

    time_offset = max(0.0, opt_config.evaluation_time_offset)

    cost = list()
    evals = list()

    ########################################################################
    # Storing trajectories for later comparison
    ########################################################################
    desired = dict()
    traj = list()
    error_t = list()
    error_vec = list()
    error_yaw_vec = list()
    t_cur = None
    vec_cur = None
    t_force = None
    vec_force = None
    vec_torque = None
    kpi_results = list()

    result_folders = dict()

    smac_results = list()
    with open(smac_file, 'r') as s_file:
        for line in s_file:
            smac_results.append(line)

    ########################################################################
    # Plot SMAC costs
    ########################################################################
    plot_cost(smac_file, args.output_dir)

    ########################################################################
    # Plot error and trajectories
    ########################################################################
    if args.simulate:
        # Simulate the scenario with the initial parameters
        result_folders[0] = run_simulation(0, smac_results, args.output_dir)

        # Simulate the scenario with the optimal parameters
        result_folders[len(smac_results) - 1] = run_simulation(len(smac_results) - 1, smac_results, args.output_dir)

        plot_trajectories(result_folders, args.output_dir)

        # with open(smac_file, 'r') as s_file:
        #     for line in s_file:
        #         smac_result = json.loads(line)
        #         sub_result_folder = os.path.join(os.getcwd(), args.output_dir, '%d' % idx)

        #         result_folders[idx] = dict()

        #         cost.append(smac_result['cost'])
        #         evals.append(smac_result['evaluations'])

        #         if not os.path.isdir(sub_result_folder):
        #             os.makedirs(sub_result_folder)

        #         # Store the partial result in the folder
        #         with open(os.path.join(sub_result_folder, 'partial_result.json'), 'w') as p_res:
        #             p_res.write(json.dumps(smac_result))

        #         parsed_params = dict()

        #         for item in smac_result['incumbent']:
        #             tag, value = item.split('=')
        #             parsed_params[tag] = float(value[1:-1])

        #         opt_config.params = parsed_params
        #         opt_config.results_dir = sub_result_folder

                # params = parse_input(parsed_params, opt_config['input_map'])

                # task = os.path.join(args.input_dir, opt_config['task'])

                # failed_tasks = list()
                # output, failed_tasks = start_simulation_pool(1, output_dir=sub_result_folder)

                # for task in opt_config.tasks:
                #     task_folder = task.split('/')[-1]
                #     task_folder = task_folder.split('.')[0]

                #     runner = SimulationRunner(
                #         parsed_params, task, os.path.join(sub_result_folder, task_folder),
                #         True, add_folder_timestamp=False)
                #     runner.run(parsed_params)

                #     result_folders[idx][task] = dict(
                #         recording_filename=runner.recording_filename,
                #         results_dir=runner.current_sim_results_dir)

                #     print 'SIMULATION RESULT DIR=', runner.current_sim_results_dir
                #     sim_eval = Evaluation(runner.recording_filename,
                #                         runner.current_sim_results_dir,
                #                         time_offset=time_offset)
                #     sim_eval.compute_kpis()
                #     sim_eval.save_evaluation()

                #     desired = dict()
                #     traj = list()
                #     error_t = list()
                #     error_vec = list()
                #     error_yaw_vec = list()
                #     t_cur = None
                #     vec_cur = None
                #     t_force = None
                #     vec_force = None
                #     vec_torque = None
                #     kpi_results = list()

                # if desired is None:
                #     desired = sim_eval.recording.parsers['trajectory'].reference.points

                # traj.append(sim_eval.recording.parsers['trajectory'].odometry.points)

                # error_t.append(sim_eval._error_set.get_time())
                # error_vec.append(KPI.get_error(sim_eval._error_set.get_data('position')))
                # error_yaw_vec.append(sim_eval._error_set.get_data('yaw'))

                # if t_cur is None:
                #     t_cur, vec_cur = sim_eval.recording.parsers['current_velocity'].current_velocity

                # if t_force is None:
                #     t_force, vec_force, vec_torque = sim_eval.recording.parsers['wrench_perturbation'].disturbances

                # kpis = sim_eval.get_kpis()

                # kpi_results.append(kpis)

                # cf = CostFunction()
                # cf.from_dict(opt_config._opt_config['cost_fcn'])
                # cf.set_kpis(sim_eval.get_kpis())

                # if 'constraints' in opt_config._opt_config:
                #     assert type(opt_config._opt_config['constraints']) == list, 'Constraints must defined on a list'
                #     cf.add_constraints(opt_config._opt_config['constraints'])

                # cur_cost = cf.compute()

                # with open(os.path.join(runner.current_sim_results_dir, 'smac_result.yaml'), 'w') as smac_file:
                #     yaml.dump(dict(cost=float(cur_cost)), smac_file, default_flow_style=False)

                # cf.save(runner.current_sim_results_dir)

                # del sim_eval
                # del runner

                # idx += 1
    else:
        print 'Reprocessing the best results...'
        print 'Opening the results directory: ', args.output_dir

        for item in sorted(os.listdir(args.output_dir)):
            subdir = os.path.join(args.output_dir, item)
            partial_result_file = os.path.join(subdir, 'partial_result.json')

            idx = int(item)
            result_folders[idx] = dict()

            if os.path.isfile(partial_result_file):
                with open(partial_result_file, 'r') as s_file:
                    for line in s_file:
                        smac_result = json.loads(line)
                        cost.append(smac_result['cost'])
                        evals.append(smac_result['evaluations'])

            if os.path.isdir(subdir):
                bag_path = subdir
                bag_filename = os.path.join(bag_path, 'recording.bag')
                if os.path.isfile(bag_filename):

                    result_folders[idx][task] = bag_filename
                    print bag_filename
                    sim_eval = Evaluation(bag_filename, bag_path, time_offset=time_offset)
                    sim_eval.compute_kpis()
                    sim_eval.save_evaluation()

                    if desired is None:
                        desired = sim_eval.recording.parsers['trajectory'].reference.points

                    traj.append(sim_eval.recording.parsers['trajectory'].odometry.points)

                    error_t.append(sim_eval._error_set.get_time())
                    error_vec.append(KPI.get_error(sim_eval._error_set.get_data('position')))
                    error_yaw_vec.append(sim_eval._error_set.get_data('yaw'))

                    if t_cur is None:
                        t_cur, vec_cur = sim_eval.recording.parsers['current_velocity'].current_velocity

                    if t_force is None:
                        t_force, vec_force, vec_torque = sim_eval.recording.parsers['wrench_perturbation'].disturbances

                    kpis = sim_eval.get_kpis()

                    kpi_results.append(kpis)

                    cf = CostFunction()
                    cf.from_dict(opt_config['cost_fcn'])
                    cf.set_kpis(sim_eval.get_kpis())

                    if 'constraints' in opt_config:
                        assert type(opt_config['constraints']) == list, 'Constraints must defined on a list'
                        cf.add_constraints(opt_config['constraints'])

                    cur_cost = cf.compute()

                    with open(os.path.join(bag_path, 'smac_result.yaml'), 'w') as smac_file:
                        yaml.dump(dict(cost=float(cur_cost)), smac_file, default_flow_style=False)

                    cf.save(bag_path)

                    print 'COST=', cur_cost
                    del sim_eval
                    idx += 1

    # # try:
    # ########################################################################
    # # Plot cost function evolution
    # ########################################################################

    # cost[0] = cost[1]
    # fig = plt.figure(figsize=(6, 4))
    # ax = fig.add_subplot(111)

    # ax.plot(evals, cost, '--b', linewidth=3, zorder=1)
    # ax.scatter(evals, cost, s=60, color='red', zorder=2)

    # ax.set_xlabel('Number of evaluations', fontsize=20)
    # ax.set_ylabel('Cost function', fontsize=20)
    # ax.tick_params(axis='both', labelsize=18)
    # ax.grid(True)
    # ax.set_xlim(np.min(evals), np.max(evals))
    # plt.tight_layout()

    # filename = os.path.join(args.output_dir, 'smac_evolution.pdf')
    # plt.savefig(filename)
    # plt.clf()

    # ########################################################################
    # # Compare first and last trajectories
    # ########################################################################

    # fig = plt.figure(figsize=(12, 8))
    # ax = fig.gca(projection='3d')

    # ax.plot(
    #     [d.x for d in desired],
    #     [d.y for d in desired],
    #     [d.z for d in desired], 'b--', label='Desired path', linewidth=3)
    # ax.plot(
    #     [d.x for d in traj[1]],
    #     [d.y for d in traj[1]],
    #     [d.z for d in traj[1]], 'g', label='Initial set', linewidth=3)
    # ax.plot(
    #     [d.x for d in traj[-1]],
    #     [d.y for d in traj[-1]],
    #     [d.z for d in traj[-1]], 'r', label='Optimal set', linewidth=3)

    # ax.set_xlabel('X [m]', fontsize=20)
    # ax.set_ylabel('Y [m]', fontsize=20)
    # ax.set_zlabel('Z [m]', fontsize=20)

    # ax.tick_params(axis='x', labelsize=18)
    # ax.tick_params(axis='y', labelsize=18)
    # ax.tick_params(axis='z', labelsize=18)

    # ax.xaxis.labelpad = 10
    # ax.yaxis.labelpad = 10
    # ax.zaxis.labelpad = 10

    # ax.legend(loc='upper left', fancybox=True, framealpha=0.8, fontsize=18)
    # ax.grid(True)
    # plt.tight_layout()

    # filename = os.path.join(args.output_dir, 'trajectories_comparison.pdf')
    # plt.savefig(filename)
    # plt.clf()

    # ########################################################################
    # # Compare first and last KPIs
    # ########################################################################

    # fig = plt.figure(figsize=(8, 12))

    # kpi_labels = dict(rmse_position='RMS Error - Position',
    #                     rmse_yaw='RMS Error - Yaw',
    #                     rmse_linear_velocity='RMS Error - Linear velocity',
    #                     rmse_angular_velocity='RMS Error - Angular velocity',
    #                     mean_abs_thrust='Mean abs. thrust')

    # i = 1
    # for tag in kpi_labels:
    #     ax = fig.add_subplot(len(kpi_labels.keys()), 1, i)
    #     ax.plot(np.arange(idx), [kpi_results[k][tag] for k in np.arange(idx)], '--b', linewidth=2, zorder=1)
    #     ax.scatter(np.arange(idx), [kpi_results[k][tag] for k in np.arange(idx)], s=30, color='red', zorder=2)
    #     i += 1

    #     ax.set_xlabel('Set index', fontsize=20)
    #     ax.set_ylabel('Metric value', fontsize=20)
    #     ax.set_title(kpi_labels[tag], fontsize=22)
    #     ax.tick_params(axis='both', labelsize=15)
    #     ax.grid(True)
    #     ax.set_xlim(0, idx - 1)

    # plt.tight_layout()
    # filename = os.path.join(args.output_dir, 'kpis_comparison.pdf')
    # plt.savefig(filename)
    # plt.clf()

    # ########################################################################
    # # Compare position error
    # ########################################################################

    # fig = plt.figure(figsize=(10, 6))

    # # Plot position error
    # ax = fig.add_subplot(211)

    # ax.plot(error_t[0], error_vec[0], color='#E2742B', linewidth=3, label='Initial set')
    # ax.plot(error_t[-1], error_vec[-1], color='#6600CC', linewidth=3, label='Optimal set')

    # error_max = np.max([np.max(error_vec[0]), np.max(error_vec[-1])])
    # if vec_cur is not None:
    #     v = np.array([np.sqrt(v[0]**2 + v[1]**2 + v[2]**2) for v in vec_cur])
    #     if v.max() > 0:
    #         v[v > 0] = 1.05
    #         ax.fill_between(t_cur, 0, v * error_max, facecolor='blue', alpha=0.2, label='Current disturbance activated')

    # if vec_force is not None:
    #     f = np.array([np.sqrt(v[0]**2 + v[1]**2 + v[2]**2) for v in vec_force])
    #     tau = np.array([np.sqrt(v[0]**2 + v[1]**2 + v[2]**2) for v in vec_torque])

    #     if f.max() > 0:
    #         f[f > 0] = 1.05
    #         ax.fill_between(t_force, 0, f * error_max, facecolor='red', alpha=0.2, label='Force disturbance activated')

    #     if tau.max() > 0:
    #         tau[tau > 0] = 1.05
    #         ax.fill_between(t_force, 0, tau * error_max, facecolor='green', alpha=0.2, label='Torque disturbance activated')

    # ax.set_xlabel('Time [s]', fontsize=20)
    # ax.set_ylabel('Position error [m]', fontsize=20)
    # ax.legend(fancybox=True, framealpha=0.9, loc='upper left', fontsize=16)
    # ax.grid(True)
    # ax.tick_params(axis='both', labelsize=15)
    # ax.set_xlim(np.min(error_t[0]), np.max(error_t[0]))
    # ax.set_ylim(0, error_max * 1.05)

    # # Plot heading error
    # ax = fig.add_subplot(212)

    # ax.plot(error_t[0], error_yaw_vec[0], color='#E2742B', linewidth=3, label='Initial set')
    # ax.plot(error_t[-1], error_yaw_vec[-1], color='#6600CC', linewidth=3, label='Optimal set')

    # error_max = np.max([np.max(error_yaw_vec[0]), np.max(error_yaw_vec[-1])])
    # error_min = np.min([np.min(error_yaw_vec[0]), np.min(error_yaw_vec[-1])])
    # if vec_cur is not None:
    #     v = np.array([np.sqrt(v[0]**2 + v[1]**2 + v[2]**2) for v in vec_cur])
    #     if v.max() > 0:
    #         v[v > 0] = 1.05
    #         ax.fill_between(t_cur, v * error_min, v * error_max, facecolor='blue', alpha=0.2, label='Current disturbance activated')

    # if vec_force is not None:
    #     f = np.array([np.sqrt(v[0]**2 + v[1]**2 + v[2]**2) for v in vec_force])
    #     tau = np.array([np.sqrt(v[0]**2 + v[1]**2 + v[2]**2) for v in vec_torque])

    #     if f.max() > 0:
    #         f[f > 0] = 1.05
    #         ax.fill_between(t_force, f * error_min, f * error_max, facecolor='red', alpha=0.2, label='Force disturbance activated')

    #     if tau.max() > 0:
    #         tau[tau > 0] = 1.05
    #         ax.fill_between(t_force, tau * error_min, tau * error_max, facecolor='green', alpha=0.2, label='Torque disturbance activated')

    # ax.set_xlabel('Time [s]', fontsize=20)
    # ax.set_ylabel('Heading error [rad]', fontsize=20)
    # ax.legend(fancybox=True, framealpha=0.9, loc='upper left', fontsize=16)
    # ax.grid(True)
    # ax.tick_params(axis='both', labelsize=15)
    # ax.set_xlim(np.min(error_t[0]), np.max(error_t[0]))
    # ax.set_ylim(error_min * 1.05, error_max * 1.05)

    # plt.tight_layout()

    # filename = os.path.join(args.output_dir, 'error_comparison.pdf')
    # plt.savefig(filename)
    # plt.clf()
    # # except Exception, e:
    # #     print 'Error while plotting comparative results, message=', str(e)
