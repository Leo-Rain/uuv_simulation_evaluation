#!/usr/bin/env python
# Copyright (c) 2016 The UUV Simulator Authors.
# All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
from __future__ import print_function
import os
import matplotlib
if os.environ.get('DISPLAY', '') == '':
    print('No display found, using non-interactive Agg backend')
    matplotlib.use('Agg', force=True)
else:
    print('Display found=', os.environ.get('DISPLAY', ''))
import argparse
import signal
import roslib
import rospy
import sys
import yaml
import itertools
import logging
import psutil
import shutil
import numpy as np
from time import sleep, gmtime, strftime
from copy import deepcopy
from uuv_simulation_runner import SimulationRunner
from uuv_bag_evaluation import Evaluation
from uuv_cost_function import CostFunction
from uuv_smac_utils import OptConfiguration, start_simulation_pool, \
    stop_simulation_pool


roslib.load_manifest('uuv_simulation_wrapper')

TERMINATE_PROCS = False

def signal_handler(signal, frame):
    print('SIGNAL RECEIVED=' + str(signal))
    with open('UUV_TERMINATE', 'w+') as t_file:
        t_file.write(strftime("%Y-%m-%d_%H:%M:%S", gmtime()))
    global TERMINATE_PROCS
    TERMINATE_PROCS = True
    

signal.signal(signal.SIGTERM, signal_handler)
signal.signal(signal.SIGINT, signal_handler)


def has_task_results(output_dir, task_filename):
    results_dir = os.path.join(output_dir, 'results', task_filename.replace('.yml', ''))
    if os.path.isdir(results_dir):
        has_results = False
        for item in os.listdir(results_dir):
            if '.bag' in item or 'process_log' in item:
                print('Folder <%s> already contains results, skipping...' % results_dir)
                has_results = True
        if has_results:
            return True
    return False


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Run batch of simulations')
    parser.add_argument(
        '--task',
        type=str,
        default='task.yml')
    parser.add_argument(
        '--output_dir',
        type=str,
        default='./results')
    parser.add_argument(
        '--config_file',
        type=str,
        default='batch_process_config.yml')
    parser.add_argument(
        '--max_num_processes',
        type=int,
        default=2)

    logger = logging.getLogger('run_batch')
    out_hdlr = logging.StreamHandler(sys.stdout)
    out_hdlr.setFormatter(logging.Formatter('%(asctime)s | %(levelname)s | %(module)s | %(message)s'))
    out_hdlr.setLevel(logging.INFO)
    logger.addHandler(out_hdlr)
    logger.setLevel(logging.INFO)

    # Parse input arguments
    args = parser.parse_args(rospy.myargv()[1:])

    assert os.path.isfile(args.task), 'Task file is not a valid file'
    assert '.yml' in args.task or '.yaml' in args.task, 'Task file is not a YAML file'

    with open(args.task, 'r') as task_file:
        task_config = yaml.load(task_file)

    logger.info('Output directory = ' + args.output_dir)
    if not os.path.isdir(args.output_dir):
        os.makedirs(args.output_dir)
        logger.info('Output directory does not exist, creating <' + args.output_dir + '>')

    output_dir = os.path.abspath(args.output_dir)

    tasks_dir = os.path.join(output_dir, 'tasks')
    if not os.path.isdir(tasks_dir):
        os.makedirs(tasks_dir)
        logger.info('Task configuration directory does not exist, creating <' + tasks_dir + '>')

    # Load optimization configuration
    with open(args.config_file, 'r') as c_file:
        grid_config = yaml.load(c_file)

    assert 'parameters' in grid_config, 'List of input parameters not available'
    assert 'input_map' in grid_config, 'Input parameter map not available'

    # Generate the parameter vectors
    assert type(grid_config) == dict, 'List of parameters must be a dictionary'

    # Copy the input map
    input_map = deepcopy(grid_config['input_map'])

    # Load the cost function
    cost_function = None
    if 'cost_fcn' in grid_config:
        cost_function = CostFunction()
        if isinstance(grid_config['cost_fcn'], dict):            
            cost_function.from_dict(grid_config['cost_fcn'])
            logger.info('Cost function loaded from list')
        elif isinstance(grid_config['cost_fcn'], str):
            assert os.path.isfile(grid_config['cost_fcn']), 'Invalid cost function file'
            assert '.yml' in grid_config['cost_fcn'] or '.yaml' in grid_config['cost_fcn']
            with open(grid_config['cost_fcn']) as cf_file:
                cf = yaml.load(cf_file)                    
                assert isinstance(cf, dict)
            cost_function.from_dict(cf)
            logger.info('Cost function loaded from file, filename=' + grid_config['cost_fcn'])
        else:
            logger.error('Invalid cost function input')
            sys.exit(0)

    # Read the list of fixed parameter, if available
    fixed_params = dict()
    if 'fixed_params' in grid_config:
        if isinstance(grid_config['fixed_params'], dict):
            fixed_params = grid_config['fixed_params']
        elif isinstance(grid_config['fixed_params'], str):
            assert os.path.isfile(grid_config['fixed_params']), 'Invalid fixed parameters file'
            assert '.yml' in grid_config['fixed_params'] or '.yaml' in grid_config['fixed_params']
            with open(grid_config['fixed_params']) as fp_file:
                fixed_params = yaml.load(fp_file)
        else:
            logger.error('Invalid fixed parameter list input')
            sys.exit(0)
    
    time_offset = 0.0
    if 'time_offset' in grid_config:
        time_offset = max(0.0, grid_config['time_offset'])

    # In case the tasks folder is empty, create the tasks
    if len(os.listdir(tasks_dir)) == 0:
        use_monte_carlo = False
        if 'use_monte_carlo' in grid_config:
            use_monte_carlo = grid_config['use_monte_carlo']
        params = dict()
        for tag in grid_config['parameters']:
            param_config = grid_config['parameters'][tag]
            if type(param_config) == list:
                params[tag] = param_config
            elif not use_monte_carlo:
                params[tag] = np.linspace(param_config['min'],
                                          param_config['max'],
                                          param_config['n'])
            else:
                params[tag] = range(param_config['n'])

        counter = 0
        for p in itertools.product(*params.values()):
            temp_task_file = 'task_%d' % counter
            counter += 1
            # Copy the input map
            input_map = deepcopy(grid_config['input_map'])
            # Temporary task configuration
            temp_task = deepcopy(task_config)
            for tag, item in zip(params.keys(), p):
                for param_tag in input_map:
                    if type(input_map[param_tag]) == list:
                        for i in range(len(input_map[param_tag])):
                            if input_map[param_tag][i] == tag:
                                if type(item) == str:
                                    input_map[param_tag][i] = item
                                else:
                                    input_map[param_tag][i] = float(item)
                    else:
                        if input_map[param_tag] == tag:
                            if type(item) == str:
                                input_map[param_tag] = item
                            elif not use_monte_carlo:
                                input_map[param_tag] = float(item)
                            else:
                                input_map[param_tag] = \
                                    float(np.random.random_sample(1)[0] * \
                                    (grid_config['parameters'][tag]['max'] - grid_config['parameters'][tag]['min']) + grid_config['parameters'][tag]['min'])
                                item = input_map[param_tag]
            # Add input map to the task file
            for tag in input_map:
                temp_task['execute']['params'][tag] = input_map[tag]
            # Add fixed parameters to the task file
            for tag in fixed_params:
                temp_task['execute']['params'][tag] = fixed_params[tag]

            temp_task_file = temp_task_file.replace('.', '-')
            temp_task_file = temp_task_file.replace('/', '-')
            temp_task_file = temp_task_file.replace(':', '-')
            temp_task_file += '.yml'

            temp_task_file_full_path = os.path.join(tasks_dir, temp_task_file)
            if not os.path.isfile(temp_task_file_full_path):
                with open(temp_task_file_full_path, 'w') as gs_file:
                    yaml.dump(temp_task, gs_file, default_flow_style=False)
                logger.info('Task file created=' + os.path.basename(temp_task_file_full_path))
            else:
                logger.info('Task file already exists=' + os.path.basename(temp_task_file_full_path))
    else:
        logger.info('Tasks folder is not empty, using the tasks stored...')

    threads = dict()
    output_sim_file = os.path.join(output_dir, 'analysis.yml')

    # Find all tasks that have not been run yet
    tasks = list()
    if not os.path.isfile(output_sim_file):
        for task in sorted(os.listdir(tasks_dir)):
            if '.yml' in task or '.yaml' in task:
                tasks.append(task)
    else:
        with open(output_sim_file) as a_file:
            data = yaml.load(a_file)
        for task in sorted(os.listdir(tasks_dir)):
            if task not in data['task_file']:
                continue
            tasks.append(task)   

    batch_size = 2 * args.max_num_processes

    while len(tasks):
        sub_set_tasks = list()
        for i in range(batch_size):
            if len(tasks):
                sub_set_tasks.append(os.path.join(tasks_dir, tasks.pop()))
            else:
                break

        opt_config_config = dict(
            cost_fcn=grid_config['cost_fcn'],
            max_num_processes=args.max_num_processes,
            task=sub_set_tasks,
            store_all_results=True,
            store_kpis_only=True,
            evaluation_time_offset=0,
            output_dir=os.path.join(output_dir, 'results'))
        opt_config = OptConfiguration.get_instance(opt_config_config)
        opt_config.params = fixed_params

        failed_tasks = list()
        output, failed_tasks = start_simulation_pool(
            args.max_num_processes,
            output_dir=os.path.join(output_dir, 'results'))

        if len(failed_tasks) > 0:
            for item in failed_tasks:
                tasks.append(os.path.basename(item['task']))

        for item in output:
            sim_eval = Evaluation(
                item['recording_filename'],
                item['results_dir'],
                time_offset=0)
            sim_eval.compute_kpis()
            sim_eval.save_kpis()
            sleep(0.1)

            # Update the batch runs analysis data
            with open(item['task'], 'r') as task_file:
                task_data = yaml.load(task_file)

            sim_data = dict()

            # Getting the variables set by the batch process from the task
            # files
            for tag in input_map:
                sim_data[tag] = [task_data['execute']['params'][tag]]

            sim_data['task_file'] = [os.path.basename(item['task'])]

            if opt_config.cost_fcn is not None:
                sim_data['cost_function'] = [float(opt_config.compute_cost_fcn(sim_eval.get_kpis()))]

            # Add all KPIs to the output data
            for tag, value in sim_eval.get_kpis().items():
                sim_data[tag] = [value]
            # Just copy the dictionary of current data if the file
            # does not exist yet
            if not os.path.isfile(output_sim_file):
                output_sim_data = sim_data
            else:
                # Update the loaded data from past simulations
                with open(output_sim_file, 'r') as output_file:
                    output_sim_data = yaml.load(output_file)

                for tag in sim_data:
                    output_sim_data[tag].append(sim_data[tag][0])

            # Store and overwrite the analysis data
            with open(output_sim_file, 'w+') as output_file:
                yaml.safe_dump(output_sim_data, output_file,
                                default_flow_style=False)

            del sim_eval
            
            sleep(0.1)

        if os.path.isdir(os.path.join(output_dir, 'results')):
            shutil.rmtree(os.path.join(output_dir, 'results'))
        os.makedirs(os.path.join(output_dir, 'results'))

